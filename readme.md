# ğŸ™ï¸ NovaFlow AI Voice Agent

NovaFlow AI Voice Agent is a **web-based conversational AI application** developed as part of the **30 Days of AI Voice Agents challenge (Day 29: Final Documentation)**.

It integrates **real-time speech-to-text transcription, text-to-speech synthesis, generative AI responses, and web search capabilities** to provide a seamless voice and text interaction experience.

Built with **âš¡ FastAPI, ğŸ¤ AssemblyAI, ğŸ¤– Google Gemini, ğŸ”Š Murf AI, and ğŸŒ Tavily**, NovaFlow supports features like **file uploads for knowledge base integration, chat history, customizable settings, and deployment on Render**.

---

## âœ¨ Features

* ğŸ¤ **Real-Time Voice Interaction**: Capture audio via browser microphone, transcribe with AssemblyAI (RealtimeTranscriber), generate AI responses with Gemini, and convert to speech via Murf AI.
* ğŸ’¬ **Text-Based Interaction**: Send text queries and receive AI-generated responses.
* ğŸ“š **Knowledge Base Integration**: Upload **PDF/TXT** files for summaries or references (e.g., *â€œSummarize myfile.pdfâ€*).
* ğŸ” **Web Search**: Real-time search via **Tavily API** using queries like *search, find, look up*.
* ğŸ—‚ï¸ **Chat History**: Save, retrieve, create, and clear conversations.
* âš™ï¸ **Customizable Settings**: Configure **voice ID, speed, style, microphone sensitivity, audio quality, theme, and accent color**.
* ğŸ“§ **Email Integration**: Send responses/summaries via **Zapier webhooks**.
* ğŸ”” **Audio Feedback**: Start/Stop sound alerts (`start.mp3`, `stop.mp3`).
* ğŸ¨ **Responsive UI**: Dark theme, spinner for loading, fixed Stop button, favicon.
* â˜ï¸ **Deployment**: Hosted on **Render** for scalable access.

---

## ğŸ“‚ Folder Structure

```
VOICEAGENT/
â”‚
â”œâ”€â”€ main.py                 # âš¡ FastAPI backend (WebSocket transcription)
â”œâ”€â”€ requirements.txt        # ğŸ“¦ Python dependencies
â”œâ”€â”€ .env                    # ğŸ”‘ API keys & secrets
â”œâ”€â”€ static/                 # ğŸ¨ Static assets
â”‚   â”œâ”€â”€ index.js            # Frontend logic
â”‚   â”œâ”€â”€ style.css           # UI styles
â”‚   â”œâ”€â”€ settings.js         # Settings logic
â”‚   â”œâ”€â”€ favicon.ico         # App icon
â”‚   â”œâ”€â”€ start.mp3           # ğŸµ Start sound
â”‚   â””â”€â”€ stop.mp3            # ğŸµ Stop sound
â”œâ”€â”€ templates/              # ğŸ–¼ï¸ HTML templates
â”‚   â”œâ”€â”€ index.html          # Main app page
â”‚   â”œâ”€â”€ home.html           # Landing page
â”‚   â”œâ”€â”€ docs.html           # Documentation page
â”‚   â””â”€â”€ settings.html       # Settings page
â”œâ”€â”€ uploads/                # ğŸ“‚ Uploaded files + chat history
â”‚   â”œâ”€â”€ knowledge_base/     # PDFs/TXTs + extracted text
â”‚   â””â”€â”€ chats/              # ğŸ’¬ JSON chat history
â””â”€â”€ settings.json           # âš™ï¸ User settings
```

---

## ğŸ› ï¸ Prerequisites

* ğŸ **Python 3.12** (backend)
* ğŸŒ **Node.js (optional)** (frontend dev)
* ğŸ”‘ **API Keys**:

  * ğŸ“ AssemblyAI â†’ `AAI_API_KEY`
  * ğŸ¤– Google Gemini â†’ `GEMINI_API_KEY`
  * ğŸ”Š Murf AI â†’ `MURF_API_KEY`
  * ğŸ” Tavily â†’ `TAVILY_API_KEY`
  * ğŸ“§ Zapier Webhook (optional) â†’ `ZAPIER_WEBHOOK_URL`
* ğŸŒ **Browser**: Chrome / Firefox (WebSocket + WebRTC support)
* â˜ï¸ **Render Account** (deployment)

---

## âš™ï¸ Setup & Installation

1. **Clone the Repository**

   ```bash
   git clone <your-repository-url>
   cd VOICEAGENT
   ```

2. **Create Virtual Environment**

   ```bash
   python -m venv venv
   .\venv\Scripts\activate  # Windows  
   source venv/bin/activate # macOS/Linux
   ```

3. **Install Dependencies**
   Add to `requirements.txt`:

   ```
   fastapi==0.112.0
   uvicorn==0.30.3
   assemblyai==0.36.0
   google-generativeai==0.8.3
   websockets==12.0
   python-dotenv==1.0.1
   aiohttp==3.9.5
   PyPDF2==3.0.1
   ```

   Install with:

   ```bash
   pip install -r requirements.txt
   ```

4. **Set Environment Variables** â†’ `.env`

   ```
   AAI_API_KEY=your_assemblyai_api_key
   GEMINI_API_KEY=your_gemini_api_key
   MURF_API_KEY=your_murf_api_key
   TAVILY_API_KEY=your_tavily_api_key
   ZAPIER_WEBHOOK_URL=your_zapier_webhook_url
   ```

5. **Create Directories**

   ```bash
   mkdir -p uploads/knowledge_base uploads/chats
   ```

6. **Add Static Files** (`favicon.ico`, `start.mp3`, `stop.mp3`) to `/static`

---

## ğŸš€ Usage

### â–¶ï¸ Run Locally

```bash
uvicorn main:app --reload
```

Open ğŸ‘‰ [http://localhost:8000/app](http://localhost:8000/app)

### ğŸ¤ Voice Interaction

1. Click **Mic Button** ğŸ™ï¸ (#micBtn)
2. Speak for â‰¥ 1 sec (*e.g., â€œTell me about AIâ€*)
3. Click **Stop Listening** ğŸ›‘ (#stopListening)
4. View transcript + AI response in chat ğŸ’¬
5. Hear reply via Murf AI ğŸ”Š

### ğŸ’¬ Text Interaction

* Type in **chat input** (#chatInput)
* Click **Send** (#sendBtn)

### ğŸ“š Knowledge Base

* Upload **PDF/TXT** via `/settings`
* Query with: *â€œSummarize myfile.pdfâ€*

### ğŸ” Web Search

* Queries like: *â€œsearch for AI trendsâ€*

### âš™ï¸ Settings

* Configure **voice, speed, conversation type, mic sensitivity, theme, accent color**
* Enable/disable **search, knowledge base, chat saving**

### ğŸ—‚ï¸ Chat History

* View chats at `/chats`
* Create new or clear history

### ğŸ“§ Email Integration

* Say *â€œsend to emailâ€* or *â€œemail the summaryâ€* â†’ Zapier

---

## â˜ï¸ Deployment on Render

1. **Push to Git**

   ```bash
   git add .
   git commit -m "Final NovaFlow AI Voice Agent for Day 29"
   git push origin main
   ```

2. **Render Setup**

   * Build Command: `pip install -r requirements.txt`
   * Start Command: `uvicorn main:app --host 0.0.0.0 --port $PORT`
   * Add environment variables

3. **Deploy & Monitor Logs** (\~5â€“10 mins)

4. Access ğŸŒ:

   ```
   https://<your-service>.onrender.com/app
   ```

   Example: `https://novaflow-agent.onrender.com/app`

---

## ğŸ Troubleshooting

* âŒ **ModuleNotFoundError: 'assemblyai.streaming'**

  * Ensure `assemblyai==0.36.0`
  * Import: `from assemblyai import RealtimeTranscriber`
  * Else: downgrade â†’ `0.26.0`

* ğŸ™ï¸ **Voice Input Issues**

  * Speak > 1 sec
  * Check API key validity
  * Allow mic access

* âš ï¸ **UI Errors**

  * Use latest `index.js` (Aug 29, 2025, 20:40 IST)
  * Ensure `favicon.ico`, `start.mp3`, `stop.mp3` exist

* ğŸŒ **Environment Issues**

  * Activate correct venv
  * Consolidate files to project root

* â˜ï¸ **Render Issues**

  * Check logs
  * Verify `requirements.txt` + `.env`

---

## âš ï¸ Known Issues

* â±ï¸ **Short Recordings** (<1s) â†’ Error
* ğŸ“„ **PDF Extraction**: Some PDFs fail, use TXT fallback
* ğŸ”Š **Murf AI Latency**: Small delays possible

---

## ğŸ¤ Contributing

1. Fork ğŸ´ the repo
2. Create branch â†’ `git checkout -b feature/your-feature`
3. Commit â†’ `git commit -m "Add your feature"`
4. Push â†’ `git push origin feature/your-feature`
5. Open a PR ğŸš€

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

---

## ğŸ™Œ Acknowledgments

* ğŸ¤ **AssemblyAI**: Real-time transcription
* ğŸ¤– **Google Gemini**: Generative AI
* ğŸ”Š **Murf AI**: TTS
* ğŸ” **Tavily**: Web search
* âš¡ **FastAPI**: Backend
* â˜ï¸ **Render**: Hosting
* ğŸ’¡ **30 Days of AI Voice Agents Challenge**: Inspiration

---

## ğŸ“¬ Contact

ğŸ’¼ Reach out on **LinkedIn** or via **GitHub Issues**.

âœ¨ Built for **Day 29 of the 30 Days of AI Voice Agents Challenge, August 2025**


